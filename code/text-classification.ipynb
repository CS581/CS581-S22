{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "1. Simple text\n",
    "2. 20 news group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = 'This doc is about machine learning.'\n",
    "d1 = 'This doc is about databases.'\n",
    "d2 = 'We investigate deep learning.'\n",
    "d3 = 'We investigate sql.'\n",
    "\n",
    "D =[d0, d1, d2, d3]\n",
    "y = ['ML', 'DB', 'ML', 'DB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 1, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0],\n",
       "        [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>databases</th>\n",
       "      <th>deep</th>\n",
       "      <th>doc</th>\n",
       "      <th>investigate</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>sql</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  databases  deep  doc  investigate  is  learning  machine  sql  this  \\\n",
       "0      1          0     0    1            0   1         1        1    0     1   \n",
       "1      1          1     0    1            0   1         0        0    0     1   \n",
       "2      0          0     1    0            1   0         1        0    0     0   \n",
       "3      0          0     0    0            1   0         0        0    1     0   \n",
       "\n",
       "   we   Y  \n",
       "0   0  ML  \n",
       "1   0  DB  \n",
       "2   1  ML  \n",
       "3   1  DB  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X.todense(), columns = feature_names)\n",
    "df['Y'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB(alpha=1, fit_prior=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DB', 'ML'], dtype='<U2')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Counts</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Counts   Y\n",
       "0     2.0  DB\n",
       "1     2.0  ML"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.class_count_, columns = ['Counts'])\n",
    "df['Y'] = clf.classes_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>databases</th>\n",
       "      <th>deep</th>\n",
       "      <th>doc</th>\n",
       "      <th>investigate</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>sql</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  databases  deep  doc  investigate   is  learning  machine  sql  \\\n",
       "0    1.0        1.0   0.0  1.0          1.0  1.0       0.0      0.0  1.0   \n",
       "1    1.0        0.0   1.0  1.0          1.0  1.0       2.0      1.0  0.0   \n",
       "\n",
       "   this   we   Y  \n",
       "0   1.0  1.0  DB  \n",
       "1   1.0  1.0  ML  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.feature_count_, columns = feature_names)\n",
    "df['Y'] = clf.classes_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>databases</th>\n",
       "      <th>deep</th>\n",
       "      <th>doc</th>\n",
       "      <th>investigate</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>sql</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  databases  deep  doc  investigate   is  learning  machine   sql  \\\n",
       "0    0.5       0.50  0.25  0.5          0.5  0.5      0.25     0.25  0.50   \n",
       "1    0.5       0.25  0.50  0.5          0.5  0.5      0.75     0.50  0.25   \n",
       "\n",
       "   this   we   Y  \n",
       "0   0.5  0.5  DB  \n",
       "1   0.5  0.5  ML  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.exp(clf.feature_log_prob_), columns = feature_names)\n",
    "df['Y'] = clf.classes_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>databases</th>\n",
       "      <th>deep</th>\n",
       "      <th>doc</th>\n",
       "      <th>investigate</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>sql</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  databases  deep  doc  investigate   is  learning  machine   sql  \\\n",
       "0    0.5       0.50  0.75  0.5          0.5  0.5      0.75     0.75  0.50   \n",
       "1    0.5       0.75  0.50  0.5          0.5  0.5      0.25     0.50  0.75   \n",
       "\n",
       "   this   we   Y  \n",
       "0   0.5  0.5  DB  \n",
       "1   0.5  0.5  ML  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(1-np.exp(clf.feature_log_prob_), columns = feature_names)\n",
    "df['Y'] = clf.classes_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>databases</th>\n",
       "      <th>deep</th>\n",
       "      <th>doc</th>\n",
       "      <th>investigate</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>sql</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.287682</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      about  databases      deep       doc  investigate        is  learning  \\\n",
       "0 -0.693147  -0.693147 -1.386294 -0.693147    -0.693147 -0.693147 -1.386294   \n",
       "1 -0.693147  -1.386294 -0.693147 -0.693147    -0.693147 -0.693147 -0.287682   \n",
       "\n",
       "    machine       sql      this        we   Y  \n",
       "0 -1.386294 -0.693147 -0.693147 -0.693147  DB  \n",
       "1 -0.693147 -1.386294 -0.693147 -0.693147  ML  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.feature_log_prob_, columns = feature_names)\n",
    "df['Y'] = clf.classes_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = ['Learning.']\n",
    "X_test = vectorizer.transform(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.75]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior:  [0.5 0.5]\n",
      "\n",
      "about\n",
      "Doc doesn't have it.\n",
      "0.5 0.5\n",
      "[0.25 0.25]\n",
      "[0.5 0.5]\n",
      "\n",
      "databases\n",
      "Doc doesn't have it.\n",
      "0.5 0.75\n",
      "[0.125  0.1875]\n",
      "[0.4 0.6]\n",
      "\n",
      "deep\n",
      "Doc doesn't have it.\n",
      "0.75 0.5\n",
      "[0.09375 0.09375]\n",
      "[0.5 0.5]\n",
      "\n",
      "doc\n",
      "Doc doesn't have it.\n",
      "0.5 0.5\n",
      "[0.046875 0.046875]\n",
      "[0.5 0.5]\n",
      "\n",
      "investigate\n",
      "Doc doesn't have it.\n",
      "0.5 0.5\n",
      "[0.0234375 0.0234375]\n",
      "[0.5 0.5]\n",
      "\n",
      "is\n",
      "Doc doesn't have it.\n",
      "0.5 0.5\n",
      "[0.01171875 0.01171875]\n",
      "[0.5 0.5]\n",
      "\n",
      "learning\n",
      "Doc has it.\n",
      "0.25 0.7500000000000001\n",
      "[0.00292969 0.00878906]\n",
      "[0.25 0.75]\n",
      "\n",
      "machine\n",
      "Doc doesn't have it.\n",
      "0.75 0.5\n",
      "[0.00219727 0.00439453]\n",
      "[0.33333333 0.66666667]\n",
      "\n",
      "sql\n",
      "Doc doesn't have it.\n",
      "0.5 0.75\n",
      "[0.00109863 0.0032959 ]\n",
      "[0.25 0.75]\n",
      "\n",
      "this\n",
      "Doc doesn't have it.\n",
      "0.5 0.5\n",
      "[0.00054932 0.00164795]\n",
      "[0.25 0.75]\n",
      "\n",
      "we\n",
      "Doc doesn't have it.\n",
      "0.5 0.5\n",
      "[0.00027466 0.00082397]\n",
      "[0.25 0.75]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = np.ones(2)\n",
    "\n",
    "p *= np.exp(clf.class_log_prior_)\n",
    "\n",
    "\n",
    "print(\"Prior: \", p)\n",
    "print()\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    print(feature_names[i])\n",
    "    if i in X_test[0].indices:\n",
    "        print(\"Doc has it.\")\n",
    "        print(np.exp(clf.feature_log_prob_[0][i]), np.exp(clf.feature_log_prob_[1][i]))\n",
    "\n",
    "        p *= np.exp(clf.feature_log_prob_[:, i])\n",
    "\n",
    "    else:\n",
    "        print(\"Doc doesn't have it.\")\n",
    "        print(1-np.exp(clf.feature_log_prob_[0][i]), 1-np.exp(clf.feature_log_prob_[1][i]))\n",
    "\n",
    "        p *= (1-np.exp(clf.feature_log_prob_[:, i]))\n",
    "    \n",
    "    print(p)\n",
    "    print(p/p.sum())\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DB', 'ML'], dtype='<U2')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Counts</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Counts   Y\n",
       "0     2.0  DB\n",
       "1     2.0  ML"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.class_count_, columns = ['Counts'])\n",
    "df['Y'] = clf.classes_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>databases</th>\n",
       "      <th>deep</th>\n",
       "      <th>doc</th>\n",
       "      <th>investigate</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>sql</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  databases  deep  doc  investigate   is  learning  machine  sql  \\\n",
       "0    1.0        1.0   0.0  1.0          1.0  1.0       0.0      0.0  1.0   \n",
       "1    1.0        0.0   1.0  1.0          1.0  1.0       2.0      1.0  0.0   \n",
       "\n",
       "   this   we   Y  \n",
       "0   1.0  1.0  DB  \n",
       "1   1.0  1.0  ML  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.feature_count_, columns = feature_names)\n",
    "df['Y'] = clf.classes_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>databases</th>\n",
       "      <th>deep</th>\n",
       "      <th>doc</th>\n",
       "      <th>investigate</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>sql</th>\n",
       "      <th>this</th>\n",
       "      <th>we</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      about  databases      deep       doc  investigate        is  learning  \\\n",
       "0  0.105263   0.105263  0.052632  0.105263     0.105263  0.105263  0.052632   \n",
       "1  0.095238   0.047619  0.095238  0.095238     0.095238  0.095238  0.142857   \n",
       "\n",
       "    machine       sql      this        we   Y  \n",
       "0  0.052632  0.105263  0.105263  0.105263  DB  \n",
       "1  0.095238  0.047619  0.095238  0.095238  ML  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.exp(clf.feature_log_prob_), columns = feature_names)\n",
    "df['Y'] = clf.classes_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8., 10.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(clf.feature_count_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26923077, 0.73076923]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.31218639, -0.31365756]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_log_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior:  [0.5 0.5]\n",
      "[-0.69314718 -0.69314718]\n",
      "\n",
      "about\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.5 0.5]\n",
      "[0.5 0.5]\n",
      "[-0.69314718 -0.69314718]\n",
      "\n",
      "databases\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.5 0.5]\n",
      "[0.5 0.5]\n",
      "[-0.69314718 -0.69314718]\n",
      "\n",
      "deep\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.5 0.5]\n",
      "[0.5 0.5]\n",
      "[-0.69314718 -0.69314718]\n",
      "\n",
      "doc\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.5 0.5]\n",
      "[0.5 0.5]\n",
      "[-0.69314718 -0.69314718]\n",
      "\n",
      "investigate\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.5 0.5]\n",
      "[0.5 0.5]\n",
      "[-0.69314718 -0.69314718]\n",
      "\n",
      "is\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.5 0.5]\n",
      "[0.5 0.5]\n",
      "[-0.69314718 -0.69314718]\n",
      "\n",
      "learning\n",
      "Doc has it.\n",
      "0.05263157894736843 0.14285714285714288\n",
      "[0.02631579 0.07142857]\n",
      "[0.26923077 0.73076923]\n",
      "[-3.63758616 -2.63905733]\n",
      "\n",
      "machine\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.02631579 0.07142857]\n",
      "[0.26923077 0.73076923]\n",
      "[-3.63758616 -2.63905733]\n",
      "\n",
      "sql\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.02631579 0.07142857]\n",
      "[0.26923077 0.73076923]\n",
      "[-3.63758616 -2.63905733]\n",
      "\n",
      "this\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.02631579 0.07142857]\n",
      "[0.26923077 0.73076923]\n",
      "[-3.63758616 -2.63905733]\n",
      "\n",
      "we\n",
      "Doc doesn't have it. Nothing done.\n",
      "[0.02631579 0.07142857]\n",
      "[0.26923077 0.73076923]\n",
      "[-3.63758616 -2.63905733]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = np.ones(2)\n",
    "\n",
    "p *= np.exp(clf.class_log_prior_)\n",
    "\n",
    "jl = np.zeros(2)\n",
    "\n",
    "jl += clf.class_log_prior_\n",
    "\n",
    "\n",
    "print(\"Prior: \", p)\n",
    "print(jl)\n",
    "print()\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    print(feature_names[i])\n",
    "    if i in X_test[0].indices:\n",
    "        print(\"Doc has it.\")\n",
    "        print(np.exp(clf.feature_log_prob_[0][i]), np.exp(clf.feature_log_prob_[1][i]))\n",
    "\n",
    "        p *= np.exp(clf.feature_log_prob_[:, i])\n",
    "\n",
    "        jl += clf.feature_log_prob_[:, i]\n",
    "\n",
    "    else:\n",
    "        print(\"Doc doesn't have it. Nothing done.\")\n",
    "    \n",
    "    print(p)\n",
    "    print(p/p.sum())\n",
    "    print(jl)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.63758616, -2.63905733])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.31218639, -0.31365756])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jl-logsumexp(jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26923077, 0.73076923])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(jl-logsumexp(jl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 News Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "#train_data = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target_names', 'filenames', 'data', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(train_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 5, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 18101)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532, 18101)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.target\n",
    "y_test = test_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_clf = BernoulliNB(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(X, y, clf, labels):\n",
    "    y_pred = clf.predict(X)\n",
    "    print(classification_report(y, y_pred, digits=3, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.724     0.562     0.633       480\n",
      "           comp.graphics      0.729     0.695     0.712       584\n",
      " comp.os.ms-windows.misc      0.980     0.330     0.494       591\n",
      "comp.sys.ibm.pc.hardware      0.699     0.800     0.746       590\n",
      "   comp.sys.mac.hardware      0.426     0.908     0.580       578\n",
      "          comp.windows.x      0.886     0.577     0.699       593\n",
      "            misc.forsale      0.440     0.872     0.585       585\n",
      "               rec.autos      0.610     0.796     0.691       594\n",
      "         rec.motorcycles      0.294     0.918     0.445       598\n",
      "      rec.sport.baseball      0.773     0.841     0.806       597\n",
      "        rec.sport.hockey      1.000     0.647     0.785       600\n",
      "               sci.crypt      0.892     0.556     0.685       595\n",
      "         sci.electronics      0.779     0.745     0.761       591\n",
      "                 sci.med      0.990     0.643     0.780       594\n",
      "               sci.space      0.986     0.482     0.648       593\n",
      "  soc.religion.christian      0.800     0.661     0.724       599\n",
      "      talk.politics.guns      0.924     0.555     0.693       546\n",
      "   talk.politics.mideast      0.956     0.504     0.660       564\n",
      "      talk.politics.misc      0.930     0.458     0.614       465\n",
      "      talk.religion.misc      1.000     0.239     0.385       377\n",
      "\n",
      "                accuracy                          0.650     11314\n",
      "               macro avg      0.791     0.639     0.656     11314\n",
      "            weighted avg      0.786     0.650     0.662     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(X_train, y_train, bn_clf, labels = train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.390     0.295     0.336       319\n",
      "           comp.graphics      0.524     0.514     0.519       389\n",
      " comp.os.ms-windows.misc      0.818     0.069     0.126       394\n",
      "comp.sys.ibm.pc.hardware      0.500     0.622     0.555       392\n",
      "   comp.sys.mac.hardware      0.317     0.743     0.445       385\n",
      "          comp.windows.x      0.796     0.435     0.563       395\n",
      "            misc.forsale      0.389     0.826     0.529       390\n",
      "               rec.autos      0.478     0.659     0.554       396\n",
      "         rec.motorcycles      0.246     0.847     0.381       398\n",
      "      rec.sport.baseball      0.731     0.746     0.738       397\n",
      "        rec.sport.hockey      0.987     0.576     0.728       399\n",
      "               sci.crypt      0.680     0.386     0.493       396\n",
      "         sci.electronics      0.549     0.496     0.521       393\n",
      "                 sci.med      0.876     0.394     0.544       396\n",
      "               sci.space      0.837     0.391     0.533       394\n",
      "  soc.religion.christian      0.538     0.558     0.547       398\n",
      "      talk.politics.guns      0.578     0.387     0.464       364\n",
      "   talk.politics.mideast      0.890     0.428     0.578       376\n",
      "      talk.politics.misc      0.583     0.194     0.291       310\n",
      "      talk.religion.misc      0.600     0.012     0.023       251\n",
      "\n",
      "                accuracy                          0.493      7532\n",
      "               macro avg      0.615     0.479     0.473      7532\n",
      "            weighted avg      0.618     0.493     0.485      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(X_test, y_test, bn_clf, labels = train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_clf = MultinomialNB(alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.838     0.810     0.824       480\n",
      "           comp.graphics      0.795     0.803     0.799       584\n",
      " comp.os.ms-windows.misc      0.949     0.506     0.660       591\n",
      "comp.sys.ibm.pc.hardware      0.659     0.922     0.768       590\n",
      "   comp.sys.mac.hardware      0.882     0.870     0.876       578\n",
      "          comp.windows.x      0.824     0.899     0.860       593\n",
      "            misc.forsale      0.888     0.824     0.855       585\n",
      "               rec.autos      0.862     0.848     0.855       594\n",
      "         rec.motorcycles      0.878     0.866     0.872       598\n",
      "      rec.sport.baseball      0.941     0.881     0.910       597\n",
      "        rec.sport.hockey      0.629     0.918     0.747       600\n",
      "               sci.crypt      0.916     0.881     0.898       595\n",
      "         sci.electronics      0.884     0.822     0.852       591\n",
      "                 sci.med      0.940     0.889     0.913       594\n",
      "               sci.space      0.959     0.823     0.886       593\n",
      "  soc.religion.christian      0.643     0.955     0.769       599\n",
      "      talk.politics.guns      0.874     0.901     0.887       546\n",
      "   talk.politics.mideast      0.952     0.801     0.870       564\n",
      "      talk.politics.misc      0.876     0.824     0.849       465\n",
      "      talk.religion.misc      0.969     0.493     0.654       377\n",
      "\n",
      "                accuracy                          0.833     11314\n",
      "               macro avg      0.858     0.827     0.830     11314\n",
      "            weighted avg      0.855     0.833     0.833     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(X_train, y_train, mn_clf, labels = train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.526     0.382     0.443       319\n",
      "           comp.graphics      0.592     0.656     0.622       389\n",
      " comp.os.ms-windows.misc      0.742     0.168     0.273       394\n",
      "comp.sys.ibm.pc.hardware      0.478     0.791     0.596       392\n",
      "   comp.sys.mac.hardware      0.674     0.639     0.656       385\n",
      "          comp.windows.x      0.720     0.742     0.731       395\n",
      "            misc.forsale      0.818     0.726     0.769       390\n",
      "               rec.autos      0.732     0.710     0.721       396\n",
      "         rec.motorcycles      0.720     0.719     0.719       398\n",
      "      rec.sport.baseball      0.892     0.788     0.837       397\n",
      "        rec.sport.hockey      0.594     0.870     0.706       399\n",
      "               sci.crypt      0.722     0.720     0.721       396\n",
      "         sci.electronics      0.630     0.560     0.593       393\n",
      "                 sci.med      0.801     0.720     0.758       396\n",
      "               sci.space      0.804     0.695     0.746       394\n",
      "  soc.religion.christian      0.422     0.897     0.574       398\n",
      "      talk.politics.guns      0.546     0.695     0.612       364\n",
      "   talk.politics.mideast      0.828     0.678     0.746       376\n",
      "      talk.politics.misc      0.605     0.381     0.467       310\n",
      "      talk.religion.misc      0.489     0.088     0.149       251\n",
      "\n",
      "                accuracy                          0.647      7532\n",
      "               macro avg      0.667     0.631     0.622      7532\n",
      "            weighted avg      0.672     0.647     0.634      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(X_test, y_test, mn_clf, labels = train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbilg\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.998     0.973     0.985       480\n",
      "           comp.graphics      0.993     0.962     0.977       584\n",
      " comp.os.ms-windows.misc      0.989     0.953     0.971       591\n",
      "comp.sys.ibm.pc.hardware      0.998     0.969     0.984       590\n",
      "   comp.sys.mac.hardware      0.989     0.958     0.974       578\n",
      "          comp.windows.x      0.998     0.987     0.992       593\n",
      "            misc.forsale      0.985     0.983     0.984       585\n",
      "               rec.autos      0.977     0.944     0.961       594\n",
      "         rec.motorcycles      0.993     0.970     0.981       598\n",
      "      rec.sport.baseball      0.668     0.995     0.799       597\n",
      "        rec.sport.hockey      1.000     0.970     0.985       600\n",
      "               sci.crypt      1.000     0.975     0.987       595\n",
      "         sci.electronics      0.998     0.968     0.983       591\n",
      "                 sci.med      1.000     0.966     0.983       594\n",
      "               sci.space      0.997     0.971     0.984       593\n",
      "  soc.religion.christian      1.000     0.983     0.992       599\n",
      "      talk.politics.guns      1.000     0.974     0.987       546\n",
      "   talk.politics.mideast      0.998     0.970     0.984       564\n",
      "      talk.politics.misc      1.000     0.963     0.981       465\n",
      "      talk.religion.misc      1.000     0.947     0.973       377\n",
      "\n",
      "                accuracy                          0.970     11314\n",
      "               macro avg      0.979     0.969     0.972     11314\n",
      "            weighted avg      0.978     0.970     0.972     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(X_train, y_train, lr_clf, labels = train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.409     0.420     0.414       319\n",
      "           comp.graphics      0.551     0.614     0.581       389\n",
      " comp.os.ms-windows.misc      0.548     0.546     0.547       394\n",
      "comp.sys.ibm.pc.hardware      0.574     0.556     0.565       392\n",
      "   comp.sys.mac.hardware      0.627     0.584     0.605       385\n",
      "          comp.windows.x      0.745     0.620     0.677       395\n",
      "            misc.forsale      0.758     0.749     0.754       390\n",
      "               rec.autos      0.608     0.626     0.617       396\n",
      "         rec.motorcycles      0.606     0.673     0.638       398\n",
      "      rec.sport.baseball      0.465     0.761     0.577       397\n",
      "        rec.sport.hockey      0.816     0.777     0.796       399\n",
      "               sci.crypt      0.789     0.606     0.686       396\n",
      "         sci.electronics      0.479     0.496     0.488       393\n",
      "                 sci.med      0.696     0.614     0.652       396\n",
      "               sci.space      0.626     0.650     0.638       394\n",
      "  soc.religion.christian      0.664     0.666     0.665       398\n",
      "      talk.politics.guns      0.513     0.547     0.529       364\n",
      "   talk.politics.mideast      0.695     0.630     0.661       376\n",
      "      talk.politics.misc      0.475     0.339     0.395       310\n",
      "      talk.religion.misc      0.311     0.283     0.296       251\n",
      "\n",
      "                accuracy                          0.598      7532\n",
      "               macro avg      0.598     0.588     0.589      7532\n",
      "            weighted avg      0.607     0.598     0.599      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(X_test, y_test, lr_clf, labels = train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(C=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.892     0.840     0.865       480\n",
      "           comp.graphics      0.838     0.848     0.843       584\n",
      " comp.os.ms-windows.misc      0.879     0.849     0.864       591\n",
      "comp.sys.ibm.pc.hardware      0.911     0.849     0.879       590\n",
      "   comp.sys.mac.hardware      0.904     0.862     0.882       578\n",
      "          comp.windows.x      0.928     0.887     0.907       593\n",
      "            misc.forsale      0.864     0.891     0.877       585\n",
      "               rec.autos      0.860     0.850     0.855       594\n",
      "         rec.motorcycles      0.791     0.886     0.836       598\n",
      "      rec.sport.baseball      0.518     0.955     0.672       597\n",
      "        rec.sport.hockey      0.962     0.890     0.925       600\n",
      "               sci.crypt      0.983     0.881     0.929       595\n",
      "         sci.electronics      0.903     0.846     0.873       591\n",
      "                 sci.med      0.957     0.891     0.922       594\n",
      "               sci.space      0.929     0.885     0.907       593\n",
      "  soc.religion.christian      0.954     0.898     0.925       599\n",
      "      talk.politics.guns      0.940     0.892     0.915       546\n",
      "   talk.politics.mideast      0.947     0.894     0.920       564\n",
      "      talk.politics.misc      0.966     0.862     0.911       465\n",
      "      talk.religion.misc      0.975     0.732     0.836       377\n",
      "\n",
      "                accuracy                          0.872     11314\n",
      "               macro avg      0.895     0.869     0.877     11314\n",
      "            weighted avg      0.892     0.872     0.877     11314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(X_train, y_train, lr_clf, labels = train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.441     0.448     0.445       319\n",
      "           comp.graphics      0.566     0.650     0.605       389\n",
      " comp.os.ms-windows.misc      0.602     0.548     0.574       394\n",
      "comp.sys.ibm.pc.hardware      0.639     0.569     0.602       392\n",
      "   comp.sys.mac.hardware      0.666     0.621     0.642       385\n",
      "          comp.windows.x      0.762     0.623     0.685       395\n",
      "            misc.forsale      0.727     0.772     0.749       390\n",
      "               rec.autos      0.651     0.616     0.633       396\n",
      "         rec.motorcycles      0.577     0.688     0.628       398\n",
      "      rec.sport.baseball      0.392     0.783     0.523       397\n",
      "        rec.sport.hockey      0.876     0.782     0.826       399\n",
      "               sci.crypt      0.831     0.609     0.703       396\n",
      "         sci.electronics      0.482     0.511     0.496       393\n",
      "                 sci.med      0.657     0.596     0.625       396\n",
      "               sci.space      0.621     0.652     0.636       394\n",
      "  soc.religion.christian      0.668     0.688     0.678       398\n",
      "      talk.politics.guns      0.524     0.604     0.561       364\n",
      "   talk.politics.mideast      0.751     0.649     0.696       376\n",
      "      talk.politics.misc      0.532     0.323     0.402       310\n",
      "      talk.religion.misc      0.370     0.199     0.259       251\n",
      "\n",
      "                accuracy                          0.609      7532\n",
      "               macro avg      0.617     0.597     0.598      7532\n",
      "            weighted avg      0.624     0.609     0.609      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(X_test, y_test, lr_clf, labels = train_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a328e9dafe32c48b4eaefbad3747c00d426236eea28e72508c75cbdd661723c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
